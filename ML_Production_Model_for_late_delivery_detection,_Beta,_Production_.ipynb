{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/xdwo0ZEXeZLMkNkXphxG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CaesarQuintero/MLProjectSupplyChain/blob/main/ML_Production_Model_for_late_delivery_detection%2C_Beta%2C_Production_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Overview\n",
        ">**Author's note:** I recommend reading this initial part to understand this model, this beta a full production model offers a complete model of anomalous case prediction, while reading the code it has instructions and notes that help a better interpretation.\n",
        "\n",
        "**Developed by:** Cesar Augusto Quintero Guerra 2023\n",
        "\n",
        "**Advised and reviewed by:** Johan Sanchez y Juan Lopez\n",
        "\n",
        "**Lynxus 2023**\n",
        "\n",
        "\n",
        ">Below you will find the project repository, along with all the development and planning of the project in notion including the production model.\n",
        "\n",
        "* [Github Repository](https://github.com/CaesarQuintero/MLProjectSupplyChain)\n",
        "\n",
        "* [Project in Notion](https://www.notion.so/Machine-Learning-Project-abc63e69e99643cb9eb3a51428deb061?pvs=4)\n",
        "\n",
        "* [Production Model](https://colab.research.google.com/drive/14ulBobu4QZ5tPRMG2uqvU0nkn2i1uO8L?usp=sharing)\n",
        "\n",
        "* [Linkedin](https://www.linkedin.com/in/caesarquintero/)\n",
        "\n",
        "\n",
        "## Purpose\n",
        "\n",
        "*   Create a machine learning model to predict freight delivery timeliness (on-time or late).\n",
        "*   Employ Random Forest classifier with SMOTE oversampling and Random\n",
        "* Undersampling to address class imbalance and enhance performance.\n",
        "\n",
        "## Target Audience\n",
        "* Individuals or organizations involved in freight transportation seeking to improve delivery reliability.\n",
        "\n",
        "## Additional Details: Oversampling and Undersampling\n",
        "\n",
        "### Oversampling:\n",
        "Creates additional samples of the minority class (SMOTE used in this project).\n",
        "### Undersampling:\n",
        "Removes samples from the majority class (Random Undersampling used in this project).\n",
        "<br/><br/>\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Installation Instructions\n",
        "## Prerequisites\n",
        "Python 3\n",
        "## Installation\n",
        "\n",
        "```\n",
        "pip install pandas numpy matplotlib seaborn statsmodels gradio\n",
        "```\n",
        "<br/><br/>\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Usage Instructions\n",
        "1.   **Load the dataset:**\n",
        "\n",
        "```\n",
        "data = pd.read_excel(\"MLDatasetforTest.xlsx\", usecols=desired_columns)\n",
        "\n",
        "```\n",
        "**Note**: Loading Excel files can be slow, so it is recommended to use CSV files instead.\n",
        "\n",
        "2.   **Preprocess the data (refer to code for detailed steps):**\n",
        "  * Handle null and duplicate values\n",
        "  * Remove outliers\n",
        "  * Create binary target variables for late deliveries\n",
        "\n",
        "3. **Undersample the majority class and oversample the minority class:**\n",
        "\n",
        "#### Undersampling\n",
        "```\n",
        "rus = RandomUnderSampler(sampling_strategy='majority')\n",
        "x_train_ontime, y_train_ontime = rus.fit_resample(x_train, y_train)\n",
        "```\n",
        "#### Oversampling\n",
        "```\n",
        "sm = SMOTE(sampling_strategy='minority',random_state=123)\n",
        "x_train_late, y_train_late = sm.fit_resample(x_train, y_train)\n",
        "```\n",
        "4. **Split data into training and testing sets:**\n",
        "\n",
        "```\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20)\n",
        "```\n",
        "\n",
        "5. **Combine oversampled and undersampled data:**\n",
        "\n",
        "\n",
        "```\n",
        "x_train_smote = pd.concat([x_train_late, x_train_ontime])\n",
        "y_train_smote = pd.concat([y_train_late, y_train_ontime])\n",
        "```\n",
        "\n",
        "6. **Create and train the Random Forest classifier:**\n",
        "\n",
        "```\n",
        "random_forest_model_SMOTE = RandomForestClassifier(**hyperparameters)\n",
        "random_forest_model_SMOTE.fit(x_train_smote, y_train_smote)\n",
        "```\n",
        "\n",
        "7. **Make predictions:**\n",
        "\n",
        "```\n",
        "predictions = random_forest_model_SMOTE.predict(x_test)\n",
        "```\n",
        "\n",
        "8. **Evaluate model performance:**\n",
        "\n",
        "```\n",
        "print(classification_report(y_test, predictions))\n",
        "print('Accuracy:', accuracy_score(y_test, predictions))\n",
        "```\n",
        "\n",
        "9. **Deploy the model:**\n",
        "\n",
        "* Command-line interface (1st Deployment Option)\n",
        "* Gradio web interface (2nd Deployment Option)\n",
        "\n",
        "\n",
        "## Additional Information\n",
        "\n",
        "##**Feature Importance**\n",
        "### Most influential features:\n",
        "* FreightWeight\n",
        "* Miles\n",
        "* CustomerCharges\n",
        "\n",
        "##**Hyperparameter Tuning**\n",
        "###Tuned hyperparameters:\n",
        "* n_estimators = 60\n",
        "* max_depth = 4\n",
        "\n",
        "## Troubleshooting\n",
        "\n",
        "Missing libraries: pip install missing libraries.\n",
        "Data format issues: Ensure dataset is in Excel format with specified columns.\n",
        "Model errors: Double-check code syntax and hyperparameter values.\n"
      ],
      "metadata": {
        "id": "PU7LOgB2J_3m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradio Installation"
      ],
      "metadata": {
        "id": "F3sff8VYDzU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "oNf8E8UzDrh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPgM3lpfLhzS"
      },
      "source": [
        "## Import of dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "As9XPxaP5XuR"
      },
      "outputs": [],
      "source": [
        "#Essentials\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "#Sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error, confusion_matrix,classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# SMOTE\n",
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "#Fine tunning Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UehxrxpOMJp4"
      },
      "source": [
        "## Dataset source | File route"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugBcmib4MI6x"
      },
      "outputs": [],
      "source": [
        "#File variables\n",
        "file_route = '/content/MLDatasetforTest.xlsx'\n",
        "file_name = \"MLDatasetforTest.xlsx\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking if the file is in the drive folder\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwFWtiVYTLb2",
        "outputId": "95233a1d-b01e-49f4-ea08-29c69212db3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLDatasetforTest.xlsx  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3STMeSCQDq-"
      },
      "source": [
        "### Dataload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUHTdnEJVuVQ"
      },
      "outputs": [],
      "source": [
        "# Pick Desired Columns for the model\n",
        "desired_columns = ['FreightWeight','miles','freightType','TrailerType','Broker Rep','BrokeredTime','Delivery Appointment End Time','BrokeredTime','Delivery Late Time (in Mins)','Pickup Late Time (in Mins)','OriginCity','OriginState','OriginZip','DestinationCity','DestinationState','DestinationZip','CustomerCharges']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UajNXR26P1Fa"
      },
      "outputs": [],
      "source": [
        "#Import dataset\n",
        "data = pd.read_excel(file_name,usecols =desired_columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgzIQGgWYZif"
      },
      "source": [
        "### Check for null and duplicates values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CV87zF6JrieX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0c5eb21-49c8-4cc2-d07f-139080c33337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Dataset has null values\n"
          ]
        }
      ],
      "source": [
        "#Null values\n",
        "if data.isnull().values.any():\n",
        "  print('The Dataset has null values')\n",
        "else:\n",
        "  print('The dataset has not null values')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQiJin-STGDF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e69e439-d7b5-4643-a283-d1da38299bef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset has not duplicate values\n"
          ]
        }
      ],
      "source": [
        "#Duplicate Values\n",
        "if data.duplicated().any():\n",
        "   print('The Dataset has duplicate values')\n",
        "else:\n",
        "   print('The dataset has not duplicate values')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zm4XEZZNRrJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08bdea6f-7e87-4d0a-da2f-5c580925a65d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset has 0.0% duplicated values\n"
          ]
        }
      ],
      "source": [
        "# Porcentage of Duplicates values\n",
        "pd.options.display.float_format = '{:.3f}%'.format\n",
        "duplicated_values = round(data.duplicated().mean()*100,1)\n",
        "print(f\"The dataset has {duplicated_values}% duplicated values\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFCWBm2ggN3X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f4022e4-57ff-4bc7-ed38-f1db978d58fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreightWeight                   0.000%\n",
              "miles                           0.030%\n",
              "freightType                     0.000%\n",
              "TrailerType                     0.000%\n",
              "Broker Rep                      0.000%\n",
              "BrokeredTime                    0.000%\n",
              "Pickup Late Time (in Mins)      0.162%\n",
              "Delivery Appointment End Time   0.000%\n",
              "Delivery Late Time (in Mins)    0.000%\n",
              "OriginCity                      0.000%\n",
              "OriginState                     0.000%\n",
              "OriginZip                       0.000%\n",
              "DestinationCity                 0.000%\n",
              "DestinationState                0.000%\n",
              "DestinationZip                  0.000%\n",
              "CustomerCharges                 0.000%\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Porcentage of null values\n",
        "pd.options.display.float_format = '{:.3f}%'.format\n",
        "data.isna().mean()*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYby0mVZr36M"
      },
      "source": [
        "### Data Procesing (ETL) | Statistical Normalization\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvFQpgEGajc9"
      },
      "source": [
        "Aim for remove the null values and duplicates to increase the relationships in the correlation matrix before to setting up the Linear regression machine learning model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BfhbJSLazjl"
      },
      "outputs": [],
      "source": [
        "#Columns category\n",
        "columnslessthan1percentage = [ 'Delivery Late Time (in Mins)', 'OriginZip', 'DestinationZip','Pickup Late Time (in Mins)']\n",
        "columnsgreaterthan1percentage = ['miles']\n",
        "\n",
        "#For columns with less than 1% of null values, delete null values.\n",
        "data.dropna(subset=['Delivery Late Time (in Mins)'],inplace = True)\n",
        "data.dropna(subset=['OriginZip'],inplace = True)\n",
        "data.dropna(subset=['DestinationZip'],inplace = True)\n",
        "data.dropna(subset=['Pickup Late Time (in Mins)'],inplace = True)\n",
        "\n",
        "#For columns with more than 1% of null values, fill null values with the average\n",
        "data['miles'].fillna(data['miles'].median(),inplace = True)\n",
        "\n",
        "#Removing duplicates\n",
        "data.drop_duplicates(subset=None, keep=\"first\", inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MEnv3bsmqZo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98025e3f-de1d-41ed-f7f5-86be225e5359"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset has not null values\n"
          ]
        }
      ],
      "source": [
        "#Null values\n",
        "if data.isnull().values.any():\n",
        "  print('The Dataset has null values')\n",
        "else:\n",
        "  print('The dataset has not null values')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUTUXtm_ouBd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25f067c9-b5a5-4e33-e063-3bfb109369a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreightWeight                   0.000%\n",
              "miles                           0.000%\n",
              "freightType                     0.000%\n",
              "TrailerType                     0.000%\n",
              "Broker Rep                      0.000%\n",
              "BrokeredTime                    0.000%\n",
              "Pickup Late Time (in Mins)      0.000%\n",
              "Delivery Appointment End Time   0.000%\n",
              "Delivery Late Time (in Mins)    0.000%\n",
              "OriginCity                      0.000%\n",
              "OriginState                     0.000%\n",
              "OriginZip                       0.000%\n",
              "DestinationCity                 0.000%\n",
              "DestinationState                0.000%\n",
              "DestinationZip                  0.000%\n",
              "CustomerCharges                 0.000%\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Porcentage of null values\n",
        "data.isna().mean()*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRaLCuj9UfyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "098e037f-609a-40f2-d250-6ce46f077999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset has not duplicate values\n"
          ]
        }
      ],
      "source": [
        "#Duplicate Values\n",
        "if data.duplicated().any():\n",
        "   print('The Dataset has duplicate values')\n",
        "else:\n",
        "  print('The dataset has not duplicate values')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H42bbFslUAM3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca439b12-9a74-4928-e35a-c7c403299051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0%\n"
          ]
        }
      ],
      "source": [
        "# Porcentage of Duplicates values\n",
        "pd.options.display.float_format = '{:.3f}%'.format\n",
        "duplicated_values = round(data.duplicated().mean()*100,1)\n",
        "print(f\"{duplicated_values}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNCTaFOwXi8H"
      },
      "source": [
        "### Checking and removing Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vqODl6BIe0d"
      },
      "outputs": [],
      "source": [
        "#Picking integer columns\n",
        "data = data.select_dtypes(include=[\"int64\", \"float64\"])\n",
        "# Filter values outside the range\n",
        "desired_range = (-45000, 45000)\n",
        "data = data[data[\"Delivery Late Time (in Mins)\"].between(*desired_range)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ySNKJdaYsnK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d9f82c6-e16b-4756-9b66-22c0d3d76e46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outliers in the variable : FreightWeight 1\n",
            "Outliers in the variable : miles 667\n",
            "Outliers in the variable : Pickup Late Time (in Mins) 1137\n",
            "Outliers in the variable : Delivery Late Time (in Mins) 1074\n",
            "Outliers in the variable : CustomerCharges 460\n"
          ]
        }
      ],
      "source": [
        "# Atipical Values | Outliers\n",
        "for col in data.columns:\n",
        "    Q1 = data[col].quantile(0.25)\n",
        "    Q3 = data[col].quantile(0.75)\n",
        "    iqr = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * iqr\n",
        "    upper_bound = Q3 + 1.5 * iqr\n",
        "    outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)]\n",
        "    print(\"Outliers in the variable :\", col, len(outliers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGMqju9aA3vW"
      },
      "outputs": [],
      "source": [
        "#Outliers Remover\n",
        "data = data.drop(outliers.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGednQeGBPso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efb80c4c-351c-4df4-a1b0-5e595783501c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outliers in the variable : FreightWeight 1\n",
            "Outliers in the variable : miles 387\n",
            "Outliers in the variable : Pickup Late Time (in Mins) 1099\n",
            "Outliers in the variable : Delivery Late Time (in Mins) 1028\n",
            "Outliers in the variable : CustomerCharges 319\n"
          ]
        }
      ],
      "source": [
        "# Atipical Values checker | Outliers\n",
        "for col in data.columns:\n",
        "    Q1 = data[col].quantile(0.25)\n",
        "    Q3 = data[col].quantile(0.75)\n",
        "    iqr = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * iqr\n",
        "    upper_bound = Q3 + 1.5 * iqr\n",
        "    outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)]\n",
        "    print(\"Outliers in the variable :\", col, len(outliers))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYfBuKNF5u9v"
      },
      "source": [
        "## Dataset Transformation for classification models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6blGq_d95rV"
      },
      "outputs": [],
      "source": [
        "# Create a new column pickup late\n",
        "data['Pickup late(Y/N)'] = np.where(data['Pickup Late Time (in Mins)'] > 0, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1Sjtpvjoia3"
      },
      "outputs": [],
      "source": [
        "# Create a new column Deliver late\n",
        "data['Deliver late(Y/N)'] = np.where(data['Delivery Late Time (in Mins)'] > 0, 1, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytwCqD0oTdeB"
      },
      "source": [
        "## Classification models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7yVg-9ub_zu"
      },
      "source": [
        "#### Define X and Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPIKeM1Rb_z1"
      },
      "outputs": [],
      "source": [
        "# Define the target variable\n",
        "y = data['Deliver late(Y/N)']\n",
        "\n",
        "# Select the numerical columns\n",
        "x = data[[\"FreightWeight\", \"miles\",\"CustomerCharges\"]]\n",
        "\n",
        "\n",
        "#Revisar alternativas con carrier charges en vez de customer charges"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HVvsWGQb_z2"
      },
      "source": [
        "#### Split the train Data from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYaPaYCsb_z2"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Oversample the minority class using SMOTE"
      ],
      "metadata": {
        "id": "JDktB9FiXMim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(sampling_strategy='minority',random_state=123)\n",
        "x_train_late, y_train_late = sm.fit_resample(x_train, y_train)"
      ],
      "metadata": {
        "id": "OJzUCwi6XT1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Undersample the majority class using SMOTE"
      ],
      "metadata": {
        "id": "UOnfZTtgDpqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rus = RandomUnderSampler(sampling_strategy='majority')\n",
        "x_train_ontime, y_train_ontime = rus.fit_resample(x_train, y_train)"
      ],
      "metadata": {
        "id": "dS6f9PibFLpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New Balanced Data"
      ],
      "metadata": {
        "id": "gttcWSccMZxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the oversampled late delivery data and undersampled on-time delivery data\n",
        "x_train_smote = pd.concat([x_train_late, x_train_ontime])\n",
        "y_train_smote = pd.concat([y_train_late, y_train_ontime])"
      ],
      "metadata": {
        "id": "bG9QomB5LGbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random forest Classifier with hyperparameters with SMOTE Oversampling and Undersampling"
      ],
      "metadata": {
        "id": "medkattbhrqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Using the finetuned model\n",
        "hyperparameters = {\n",
        "    \"n_estimators\": 60,\n",
        "    \"max_depth\": 4,\n",
        "}"
      ],
      "metadata": {
        "id": "RTCgbwLDhrqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Random Forest classifier\n",
        "random_forest_model_SMOTE = RandomForestClassifier(**hyperparameters)"
      ],
      "metadata": {
        "id": "WFKjck89hrqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "random_forest_model_SMOTE.fit(x_train_smote, y_train_smote)"
      ],
      "metadata": {
        "id": "8ahdgVtrhrqV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "24feac0f-6902-49ad-8106-3f13fe31c85d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=4, n_estimators=60)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=4, n_estimators=60)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=4, n_estimators=60)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "predictions = random_forest_model_SMOTE.predict(x_test)"
      ],
      "metadata": {
        "id": "wQtqh_0AhrqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "print(classification_report(y_test, predictions))\n",
        "print('Accuracy:', accuracy_score(y_test, predictions))"
      ],
      "metadata": {
        "id": "SGm6Yg_ihrqV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8e9e3eb-45b3-489d-a314-1578d2633b0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.92      0.92      1707\n",
            "           1       0.23      0.24      0.23       173\n",
            "\n",
            "    accuracy                           0.85      1880\n",
            "   macro avg       0.57      0.58      0.58      1880\n",
            "weighted avg       0.86      0.85      0.86      1880\n",
            "\n",
            "Accuracy: 0.8537234042553191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deployment option 1"
      ],
      "metadata": {
        "id": "0LSGWDh_9Pul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Offers a direct query on the model using the command terminal"
      ],
      "metadata": {
        "id": "fXokS15nZi1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Please enter the following information:')\n",
        "freight_weight = float(input('Freight weight (in pounds): '))\n",
        "miles = float(input('Miles to travel: '))\n",
        "customer_charges = float(input('Customer charges: '))\n",
        "\n",
        "# Create a dataframe with the input data\n",
        "data = pd.DataFrame({\n",
        "    'FreightWeight': [freight_weight],\n",
        "    'miles': [miles],\n",
        "    'CustomerCharges': [customer_charges]\n",
        "})\n",
        "\n",
        "# Make a prediction\n",
        "prediction = random_forest_model_SMOTE.predict(data)\n",
        "\n",
        "# Print the prediction\n",
        "if prediction > 0:\n",
        "  print('Load forecast : The load will be late')\n",
        "else:\n",
        "  print('Load forecast : The load will be on time')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1FLPMKc8x7g",
        "outputId": "19cc3c5d-a2ee-4590-b1be-53ae2c39aa88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter the following information:\n",
            "Freight weight (in pounds): 100000000\n",
            "Miles to travel: 2\n",
            "Customer charges: 1\n",
            "Load forecast : The load will be late\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deployment option 2"
      ],
      "metadata": {
        "id": "G2vThHXxEOH6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Offers a drop-down graphical interface for users"
      ],
      "metadata": {
        "id": "lU_4kXVpZdzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the inputs and outputs AS\n",
        "inputs = [\n",
        "    gr.Textbox(label='Freight weight (in pounds)'),\n",
        "    gr.Textbox(label='Miles to travel'),\n",
        "    gr.Textbox(label='Customer charges')\n",
        "]\n",
        "outputs = gr.Textbox(label='Load forecast')\n",
        "\n",
        "# Define the function that will be called when the user clicks the submit button\n",
        "def predict(freight_weight, miles, customer_charges):\n",
        "    # Convert the input strings to floats\n",
        "    freight_weight = float(freight_weight)\n",
        "    miles = float(miles)\n",
        "    customer_charges = float(customer_charges)\n",
        "\n",
        "    # Create a dataframe with the input data\n",
        "    data_for_forecast = pd.DataFrame({\n",
        "        'FreightWeight': [freight_weight],\n",
        "        'miles': [miles],\n",
        "        'CustomerCharges': [customer_charges]\n",
        "    })\n",
        "\n",
        "    # Make a prediction\n",
        "    prediction = random_forest_model_SMOTE.predict(data_for_forecast)\n",
        "\n",
        "\n",
        "\n",
        "    # Return the prediction\n",
        "    return 'The load will be ' + ('late' if prediction > 0 else 'on time')\n",
        "# Create the interface\n",
        "interface = gr.Interface(predict, inputs, outputs)\n",
        "\n",
        "# Launch the interface\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "id": "HIXjCmRPDRyk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}